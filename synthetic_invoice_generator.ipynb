{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280aa9d5-228c-4fac-9f98-d98f9c3cb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U easyocr opencv-python-headless Pillow google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93a4f97-f6ba-40ab-be46-7ff6c21af511",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-doctr[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b6519-9729-4c6e-b5de-9bacf19bf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import easyocr\n",
    "import google.generativeai as genai\n",
    "import cv2\n",
    "from PIL import Image as PILImage, ImageDraw, ImageFont\n",
    "from IPython.display import Image, display\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdad79f0-f873-43e7-b2c6-56f17e8f9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = easyocr.Reader(['en', 'de'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af44af4-7649-4218-943f-b7b4bf4f3999",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '' \n",
    "FONT_PATH_CV = cv2.FONT_HERSHEY_SIMPLEX \n",
    "OUTPUT_DIR = \"/kaggle/working/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8724b0a9-3fae-4e4e-a644-72b297cae90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTABLE_IMAGE_PATH = os.path.join(OUTPUT_DIR, \"selectable_ocr_output.png\")\n",
    "OCR_RESULTS_PATH = os.path.join(OUTPUT_DIR, \"ocr_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a129a7-bd0c-45df-8919-28c7cd90448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EasyOCR\n",
    "\n",
    "print(\"1. Performing OCR to find all text fragments...\")\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    print(f\"ðŸ›‘ ERROR: Image not found at '{IMAGE_PATH}'. Please check the path.\")\n",
    "else:\n",
    "    image = cv2.imread(IMAGE_PATH)\n",
    "    # Use paragraph=False for more granular text boxes, which is better for selection\n",
    "    ocr_results = reader.readtext(image, paragraph=False)\n",
    "    print(f\"2. Found {len(ocr_results)} text fragments.\")\n",
    "\n",
    "    # Prepare data for saving (and for the next cell)\n",
    "    output_data_for_json = []\n",
    "    output_image = image.copy() # Create a copy to draw on\n",
    "\n",
    "    # --- Print options and draw on the image ---\n",
    "    print(\"\\n--- Detected Text (for selection in Cell 2) ---\")\n",
    "    for i, (bbox, text, _) in enumerate(ocr_results):\n",
    "        text_id = i + 1  # Use 1-based IDs for user-friendliness\n",
    "        print(f\"  ID: {text_id:<4} | Text: {text}\")\n",
    "\n",
    "        # Add to the list that we will save as JSON\n",
    "        output_data_for_json.append({\n",
    "            \"id\": text_id,\n",
    "            \"bbox\": [tuple(map(int, p)) for p in bbox],\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "        # --- Draw labeled bounding boxes on the image ---\n",
    "        top_left = tuple(map(int, bbox[0]))\n",
    "        bottom_right = tuple(map(int, bbox[2]))\n",
    "        \n",
    "        cv2.rectangle(output_image, top_left, bottom_right, (0, 0, 255), 2) # Red box\n",
    "        label_pos = (top_left[0], top_left[1] - 10)\n",
    "        cv2.putText(output_image, str(text_id), label_pos, FONT_PATH_CV, 0.7, (255, 0, 0), 2) # Blue ID\n",
    "\n",
    "    # --- Save artifacts for Cell 2 and for viewing ---\n",
    "    # Save the OCR results to a file that Cell 2 can read\n",
    "    with open(OCR_RESULTS_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data_for_json, f, indent=2)\n",
    "    print(f\"\\nâœ… OCR results saved to '{OCR_RESULTS_PATH}'\")\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    cv2.imwrite(SELECTABLE_IMAGE_PATH, output_image)\n",
    "    print(f\"âœ… Selectable image with labeled boxes saved to '{SELECTABLE_IMAGE_PATH}'\")\n",
    "\n",
    "    print(\"\\n--- Visual Guide ---\")\n",
    "    # Display the image with bounding boxes directly in the notebook output\n",
    "    display(Image(filename=SELECTABLE_IMAGE_PATH, width=700))\n",
    "\n",
    "    print(\"\\nâž¡ï¸ ACTION: Go to Cell 2, edit the 'IDS_TO_REPLACE' list with the IDs you want, and run it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b784ec46-179d-41ef-8b74-823328e7b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DoCtR OCR\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"1. Performing OCR with doctR OCR line model...\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"â–¶ï¸ Running on device: {device}\")\n",
    "\n",
    "\n",
    "if not os.path.exists(IMAGE_PATH):\n",
    "    print(f\"ðŸ›‘ ERROR: Image not found at '{IMAGE_PATH}'. Please check the path.\")\n",
    "else:\n",
    "    # Load the image using doctr's supported loader\n",
    "    doc = DocumentFile.from_images(IMAGE_PATH)\n",
    "    model = ocr_predictor(det_arch='db_resnet50', reco_arch='crnn_vgg16_bn', pretrained=True)\n",
    "    model.det_predictor.model.to(device)\n",
    "    model.reco_predictor.model.to(device)\n",
    "    # Predict using doctr (extracts lines, not paragraphs)\n",
    "    result = model(doc)\n",
    "\n",
    "    # The output will contain pages, lines, and words. We'll extract lines for selection.\n",
    "    ocr_results = []\n",
    "    page = result.pages[0]\n",
    "    for block in page.blocks:\n",
    "        for line in block.lines:\n",
    "            bbox = line.geometry\n",
    "            # doctr gives bbox as relative coordinates (x_min, y_min, x_max, y_max)\n",
    "            # We'll convert them to pixel coordinates for drawing on the image\n",
    "            img = cv2.imread(IMAGE_PATH)\n",
    "            h, w = img.shape[:2]\n",
    "            x_min, y_min, x_max, y_max = bbox[0][0]*w, bbox[0][1]*h, bbox[1][0]*w, bbox[1][1]*h\n",
    "            bbox_pixels = [\n",
    "                (int(x_min), int(y_min)),\n",
    "                (int(x_max), int(y_min)),\n",
    "                (int(x_max), int(y_max)),\n",
    "                (int(x_min), int(y_max)),\n",
    "            ]\n",
    "            text = \" \".join(word.value for word in line.words)\n",
    "            ocr_results.append((bbox_pixels, text))\n",
    "\n",
    "    print(f\"2. Found {len(ocr_results)} text line fragments.\")\n",
    "\n",
    "    # Prepare data for saving\n",
    "    output_data_for_json = []\n",
    "    output_image = cv2.imread(IMAGE_PATH).copy() # Create a copy to draw on\n",
    "\n",
    "    print(\"\\n--- Detected Text (for selection in Cell 2) ---\")\n",
    "    for i, (bbox, text) in enumerate(ocr_results):\n",
    "        text_id = i + 1  # Use 1-based IDs for user-friendliness\n",
    "        print(f\"  ID: {text_id:<4} | Text: {text}\")\n",
    "\n",
    "        # Add to the JSON list\n",
    "        output_data_for_json.append({\n",
    "            \"id\": text_id,\n",
    "            \"bbox\": bbox,\n",
    "            \"text\": text\n",
    "        })\n",
    "\n",
    "        # Draw bounding boxes on the image\n",
    "        top_left = bbox[0]\n",
    "        bottom_right = bbox[2]\n",
    "        cv2.rectangle(output_image, top_left, bottom_right, (0, 0, 255), 2) # Red box\n",
    "        label_pos = (top_left[0], top_left[1] - 10)\n",
    "        cv2.putText(output_image, str(text_id), label_pos, FONT_PATH_CV, 0.7, (255, 0, 0), 2) # Blue ID\n",
    "\n",
    "    # Save OCR results to JSON\n",
    "    with open(OCR_RESULTS_PATH, 'w', encoding='utf-8') as f:\n",
    "        json.dump(output_data_for_json, f, indent=2)\n",
    "    print(f\"\\nâœ… OCR results saved to '{OCR_RESULTS_PATH}'\")\n",
    "\n",
    "    # Save the image with bounding boxes\n",
    "    cv2.imwrite(SELECTABLE_IMAGE_PATH, output_image)\n",
    "    print(f\"âœ… Selectable image with labeled boxes saved to '{SELECTABLE_IMAGE_PATH}'\")\n",
    "\n",
    "    print(\"\\n--- Visual Guide ---\")\n",
    "    display(PILImage.open(SELECTABLE_IMAGE_PATH).resize((700, int(output_image.shape[0] * 700 / output_image.shape[1]))))\n",
    "\n",
    "    print(\"\\nâž¡ï¸ ACTION: Go to Cell 2, edit the 'IDS_TO_REPLACE' list with the IDs you want, and run it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496a0994-5fec-4acb-9af1-5a84585b82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "IDS_TO_REPLACE = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2622ab-f94d-4f0d-97ef-9b8a7231a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4202b46-a87a-4b67-9e20-c6939b5a819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = genai.types.GenerationConfig(\n",
    "        temperature=0.9  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc0a77-4e48-477b-9567-229b93e47d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = \"/kaggle/working/\"\n",
    "OCR_RESULTS_PATH = os.path.join(OUTPUT_DIR, \"ocr_results.json\")\n",
    "FINAL_IMAGE_PATH = os.path.join(OUTPUT_DIR, \"final_anonymized_image.png\")\n",
    "FONT_PATH = \"/kaggle/input/arial-ttf/arial.ttf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bd4e1-1347-4cdf-8082-d41e31ff186a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OCR_RESULTS_PATH, 'r', encoding='utf-8') as f:\n",
    "    ocr_data = json.load(f)\n",
    "\n",
    "# 2. Create dictionary for selected IDs\n",
    "text_replacements = {}\n",
    "for entry in ocr_data:\n",
    "    if entry['id'] in IDS_TO_REPLACE:\n",
    "        # Corrected syntax: close bracket and use assignment operator\n",
    "        text_replacements[entry['id']] = entry['text']\n",
    "\n",
    "# 3. Print results for verification\n",
    "print(\"Selected Text Fragments for Replacement:\")\n",
    "print(json.dumps(text_replacements, indent=2))\n",
    "print(f\"\\nTotal items to replace: {len(text_replacements)}\")\n",
    "\n",
    "output_path = \"/kaggle/working/text_replacements.json\"\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(text_replacements, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nSaved JSON file to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47731ed-7a88-4d56-9d37-0651e5e49c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    api_key = \"Your api key\"\n",
    "    genai.configure(api_key=api_key)\n",
    "    print(\"âœ… Successfully configured Gemini API.\")\n",
    "except Exception as e:\n",
    "    print(f\"ðŸ›‘ ERROR: Could not configure Gemini. Please ensure you have set the 'GOOGLE_API_KEY' secret. Details: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe9b73-1218-4d07-96a9-6f3c023951f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "random_seed = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eaac18-89e5-4e3f-9098-5a6304a36803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add as many styles as you wish depending on the context\n",
    "import random\n",
    "\n",
    "style_themes = [\n",
    "    \"plain and simple\", \"traditional\"\n",
    "]\n",
    "\n",
    "chosen_theme = random.choice(style_themes)\n",
    "print(f\"Injecting random theme for this run: '{chosen_theme}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e765b7-7a96-47ba-9523-4f98e0ae6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fake_data(data, fake_map):\n",
    "    \"\"\"\n",
    "    Recursively replace all int or str leaf values in data\n",
    "    if they match a key in fake_map. Also handles comma-separated\n",
    "    strings by splitting, mapping each element, then rejoining.\n",
    "    \"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        return {k: apply_fake_data(v, fake_map) for k, v in data.items()}\n",
    "\n",
    "    elif isinstance(data, list):\n",
    "        return [apply_fake_data(item, fake_map) for item in data]\n",
    "\n",
    "    elif isinstance(data, int):\n",
    "        key = str(data)\n",
    "        if key in fake_map:\n",
    "            print(f\"Replacing {data!r} â†’ {fake_map[key]!r}\")\n",
    "            return fake_map[key]\n",
    "        else:\n",
    "            print(f\"Keeping   {data!r}\")\n",
    "            return data\n",
    "\n",
    "    elif isinstance(data, str):\n",
    "        # if it looks like a comma-separated list, handle each piece\n",
    "        if ',' in data:\n",
    "            parts = [part.strip() for part in data.split(',')]\n",
    "            new_parts = []\n",
    "            for part in parts:\n",
    "                if part in fake_map:\n",
    "                    print(f\"Replacing segment {part!r} â†’ {fake_map[part]!r}\")\n",
    "                    new_parts.append(str(fake_map[part]))\n",
    "                else:\n",
    "                    print(f\"Keeping   segment {part!r}\")\n",
    "                    new_parts.append(part)\n",
    "            return ', '.join(new_parts)\n",
    "\n",
    "        # otherwise treat as a single value\n",
    "        key = data\n",
    "        if key in fake_map:\n",
    "            print(f\"Replacing {data!r} â†’ {fake_map[key]!r}\")\n",
    "            return fake_map[key]\n",
    "        else:\n",
    "            print(f\"Keeping   {data!r}\")\n",
    "            return data\n",
    "\n",
    "    else:\n",
    "        # other types unchanged\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc231eb-e8b7-4176-a54f-b0b42fb07036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymize_selected_text(\n",
    "    original_image_path,\n",
    "    ocr_data_path,\n",
    "    ids_to_replace,\n",
    "    output_image_path=\"anonymized_output.png\",\n",
    "    output_json_path=\"anonymized_output.json\"  # âœ… NEW ARGUMENT\n",
    "):\n",
    "    \n",
    "    FINAL_IMAGE_PATH = output_image_path\n",
    "\n",
    "    print(f\"\\n1. Loading OCR data and filtering for {len(ids_to_replace)} selected IDs...\")\n",
    "    with open(ocr_data_path, 'r', encoding='utf-8') as f:\n",
    "        all_ocr_data = json.load(f)\n",
    "\n",
    "    items_to_replace = [item for item in all_ocr_data if item['id'] in ids_to_replace]\n",
    "    if not items_to_replace:\n",
    "        print(\"Warning: The IDs listed in IDS_TO_REPLACE were not found in the OCR data. Nothing to do.\")\n",
    "        return\n",
    "\n",
    "    # 2. Call Gemini to generate fake data\n",
    "    print(\"2. Calling Gemini to generate fake data...\")\n",
    "    try:\n",
    "        model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\")\n",
    "        generation_config = genai.types.GenerationConfig(temperature=2.0, top_p=0.95)\n",
    "\n",
    "        prompt_data = [{\"id\": item[\"id\"], \"text\": item[\"text\"]} for item in items_to_replace]\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "You are an expert data anonymizer for English documents. Your creative style for this task is: \"{chosen_theme}\".\n",
    "Based on the following list of items, generate a realistic but fake English replacement for each and every item(even if it is repeating) that fits your assigned style.Keep letters and numbers between (1-0) and [A-Z][a-z]\n",
    "# Respond with ONLY a single JSON object that maps the original 'id' (as a string) to the new fake text string.YOU SHOULD NOT KEEP ANYTHING REPLACE EVERYTHING EXCEPT THE PLACEHOLDERS.Don't forget to replace the tax percentage. Ensure the output is unique and creative.\n",
    "Keep the Placeholders of the values of the document same when faking the data. You should still be able to recognize if it is an invoice .\n",
    "YOU SHOULD NOT KEEP ANYTHING REPLACE EVERYTHING EXCEPT THE PLACEHOLDERS. \n",
    "Input: {json.dumps(prompt_data, indent=2, ensure_ascii=False)}\n",
    "\"\"\"\n",
    "        response = model.generate_content(prompt, generation_config=generation_config, request_options={\"timeout\": 90})\n",
    "        json_match = re.search(r'\\{.*\\}', response.text, re.DOTALL)\n",
    "        if not json_match: raise ValueError(\"No JSON object found in Gemini response.\")\n",
    "        fake_data_map = json.loads(json_match.group(0))\n",
    "        print(\"âœ… Gemini returned fake data successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ›‘ ERROR: Failed to get fake data from Gemini. Error: {e}\")\n",
    "        return\n",
    "    #Your JSON You wish to fill with the replaced values \n",
    "    with open('/kaggle/input/test-json/inv.json', 'r', encoding='utf-8') as f:\n",
    "        original_data = json.load(f)\n",
    "\n",
    "    updated_json = apply_fake_data(original_data, fake_data_map)\n",
    "\n",
    "    # âœ… Save to the custom JSON output path\n",
    "    with open(output_json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(updated_json, f, indent=2, ensure_ascii=False)\n",
    "    print(f\"âœ… Fake data mapped and saved to '{output_json_path}'\")\n",
    "\n",
    "    # 3. Inpaint and Render\n",
    "    print(\"3. Inpainting original text and rendering new text...\")\n",
    "    original_image = cv2.imread(original_image_path)\n",
    "    mask = np.zeros(original_image.shape[:2], dtype=\"uint8\")\n",
    "    for item in items_to_replace:\n",
    "        cv2.fillPoly(mask, [np.array(item['bbox'], dtype=np.int32)], (255, 255, 255))\n",
    "\n",
    "    inpainted_image_cv = cv2.inpaint(original_image, mask, inpaintRadius=5, flags=cv2.INPAINT_TELEA)\n",
    "    inpainted_image_pil = Image.fromarray(cv2.cvtColor(inpainted_image_cv, cv2.COLOR_BGR2RGB))\n",
    "    draw = ImageDraw.Draw(inpainted_image_pil)\n",
    "\n",
    "    base_font = None\n",
    "    if os.path.exists(FONT_PATH):\n",
    "        try:\n",
    "            base_font = ImageFont.truetype(FONT_PATH, 10)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load custom font {FONT_PATH}. Using default. Error: {e}\")\n",
    "            base_font = ImageFont.load_default()\n",
    "    else:\n",
    "        print(f\"Warning: Custom font at '{FONT_PATH}' not found. Using default.\")\n",
    "        base_font = ImageFont.load_default()\n",
    "\n",
    "    for item in items_to_replace:\n",
    "        new_text = fake_data_map.get(str(item['id']))\n",
    "        if not new_text: continue\n",
    "\n",
    "        bbox = item['bbox']\n",
    "        tl, _, br, _ = bbox\n",
    "        x1, y1, x2, y2 = int(tl[0]), int(tl[1]), int(br[0]), int(br[1])\n",
    "\n",
    "        box_width, box_height = x2 - x1, y2 - y1\n",
    "        if box_width <= 0 or box_height <= 0: continue\n",
    "\n",
    "        # 1. DYNAMIC FONT SIZING\n",
    "        font_size = int(box_height * 0.9)\n",
    "        font = base_font.font_variant(size=font_size)\n",
    "        \n",
    "        # Pillow >= 10.0.0 uses getbbox, older versions use getsize\n",
    "        try:\n",
    "            # Modern way\n",
    "            while font.getbbox(new_text)[2] > box_width:\n",
    "                font_size -= 1\n",
    "                if font_size < 6: font_size = 6; break\n",
    "                font = base_font.font_variant(size=font_size)\n",
    "        except AttributeError:\n",
    "             # Older way\n",
    "            while font.getsize(new_text)[0] > box_width:\n",
    "                font_size -= 1\n",
    "                if font_size < 6: font_size = 6; break\n",
    "                font = base_font.font_variant(size=font_size)\n",
    "\n",
    "        # 2. CENTER TEXT IN THE BOX\n",
    "        text_bbox = draw.textbbox((0, 0), new_text, font=font)\n",
    "        text_width = text_bbox[2] - text_bbox[0]\n",
    "        text_height = text_bbox[3] - text_bbox[1]\n",
    "        \n",
    "        position_x = x1 + (box_width - text_width) / 2\n",
    "        position_y = y1 + (box_height - text_height) / 2 - text_bbox[1]\n",
    "\n",
    "        draw.text((position_x, position_y), new_text, font=font, fill=(0, 0, 0))\n",
    "\n",
    "    inpainted_image_pil.save(output_image_path)\n",
    "    print(f\"âœ¨ Final image saved to '{output_image_path}'\")\n",
    "    return output_image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb14f9d-a5fd-492f-a3b8-41dd2fb62279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "NUM_VARIANTS = 100\n",
    "SAVE_DIR = \"output_images_1\"\n",
    "JSON_OUTPUT_DIR = \"output_jsons\"\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "os.makedirs(JSON_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "generated_paths = []\n",
    "\n",
    "for i in range(NUM_VARIANTS):\n",
    "    print(f\"\\n=== Generating variant {i+1}/{NUM_VARIANTS} ===\")\n",
    "    \n",
    "    output_filename = f\"anonymized_variant_{i+1}.png\"\n",
    "    output_path = os.path.join(SAVE_DIR, output_filename)\n",
    "\n",
    "    output_json_filename = f\"anonymized_variant_{i+1}.json\"\n",
    "    output_json_path = os.path.join(JSON_OUTPUT_DIR, output_json_filename)\n",
    "\n",
    "    anonymized_image_path = anonymize_selected_text(\n",
    "        IMAGE_PATH,\n",
    "        OCR_RESULTS_PATH,\n",
    "        IDS_TO_REPLACE,\n",
    "        output_image_path=output_path,\n",
    "        output_json_path=output_json_path  # âœ… Pass unique JSON path\n",
    "    )\n",
    "\n",
    "    if anonymized_image_path and os.path.exists(anonymized_image_path):\n",
    "        generated_paths.append(anonymized_image_path)\n",
    "        print(f\"âœ… Saved: {output_path} + {output_json_path}\")\n",
    "    else:\n",
    "        print(f\"âŒ Variant {i+1} failed to generate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61a5ee-f571-46ce-98db-e1c5c7d8230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    " \n",
    "\n",
    "folder_to_zip = '/kaggle/working/output_images'\n",
    " \n",
    "\n",
    "output_zip = '/kaggle/working/output_images.zip'\n",
    " \n",
    "\n",
    "shutil.make_archive(base_name=output_zip.replace('.zip', ''), \n",
    "                    format='zip', \n",
    "                    root_dir=folder_to_zip) \n",
    "print(f\"âœ… Zipped: {output_zip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e7bda-dab2-4cdd-b0c9-97e14d77bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    " \n",
    "# Path to your output folder\n",
    "\n",
    "folder_to_zip = '/kaggle/working/output_jsons'\n",
    " \n",
    "# Name of the zip file\n",
    "\n",
    "output_zip = '/kaggle/working/output_jsons.zip'\n",
    " \n",
    "# Make the zip\n",
    "\n",
    "shutil.make_archive(base_name=output_zip.replace('.zip', ''), \n",
    "                    format='zip', \n",
    "                    root_dir=folder_to_zip)\n",
    "print(f\"âœ… Zipped: {output_zip}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735398d5-c6e4-4cab-aa67-3df7ceca86c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
